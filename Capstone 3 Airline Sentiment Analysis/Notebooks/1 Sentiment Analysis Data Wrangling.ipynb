{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16b3d4e",
   "metadata": {},
   "source": [
    "# Airline Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4ae07",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Data Collection](#DataCollection)\n",
    "* [Data Organization](#DataOrganization)\n",
    "* [Data Definition](#DataDefinition)\n",
    "* [Data Cleaning](#DataCleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de85920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "#this will deal with punctuation\n",
    "import string\n",
    "import re\n",
    "from string import digits\n",
    "import nltk #using the Natural Language Toolkit\n",
    "from nltk.corpus import stopwords\n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9759f",
   "metadata": {},
   "source": [
    "# 1. Data Collection <a class=\"anchor\" id=\"DataCollection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af8dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "tweets = pd.read_csv(\"../Data/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034e195",
   "metadata": {},
   "source": [
    "# 2. Data Organization <a class=\"anchor\" id=\"DataOrganization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093c1148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the heading of data\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9520db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206a3e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#view summary of data\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e2c5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                            0\n",
       "airline_sentiment                   0\n",
       "airline_sentiment_confidence        0\n",
       "negativereason                   5462\n",
       "negativereason_confidence        4118\n",
       "airline                             0\n",
       "airline_sentiment_gold          14600\n",
       "name                                0\n",
       "negativereason_gold             14608\n",
       "retweet_count                       0\n",
       "text                                0\n",
       "tweet_coord                     13621\n",
       "tweet_created                       0\n",
       "tweet_location                   4733\n",
       "user_timezone                    4820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b882ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0.000000\n",
       "airline_sentiment                0.000000\n",
       "airline_sentiment_confidence     0.000000\n",
       "negativereason                  37.308743\n",
       "negativereason_confidence       28.128415\n",
       "airline                          0.000000\n",
       "airline_sentiment_gold          99.726776\n",
       "name                             0.000000\n",
       "negativereason_gold             99.781421\n",
       "retweet_count                    0.000000\n",
       "text                             0.000000\n",
       "tweet_coord                     93.039617\n",
       "tweet_created                    0.000000\n",
       "tweet_location                  32.329235\n",
       "user_timezone                   32.923497\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of null values\n",
    "((tweets.isnull().sum() * 100)/ len(tweets.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c45b9d",
   "metadata": {},
   "source": [
    "\"airline_sentiment_gold\" , \"negativereason_gold\", and \"tweet_coord\" columns are missing over 90% of their input. I will drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2c219f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline        name  \\\n",
       "0            NaN                        NaN  Virgin America     cairdin   \n",
       "1            NaN                     0.0000  Virgin America    jnardino   \n",
       "2            NaN                        NaN  Virgin America  yvonnalynn   \n",
       "3     Bad Flight                     0.7033  Virgin America    jnardino   \n",
       "4     Can't Tell                     1.0000  Virgin America    jnardino   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                @VirginAmerica What @dhepburn said.   \n",
       "1              0  @VirginAmerica plus you've added commercials t...   \n",
       "2              0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3              0  @VirginAmerica it's really aggressive to blast...   \n",
       "4              0  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(columns=[\"airline_sentiment_gold\" , \"negativereason_gold\", \"tweet_coord\"])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4799a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id                           0\n",
      "airline_sentiment                  0\n",
      "airline_sentiment_confidence       0\n",
      "negativereason                  5462\n",
      "negativereason_confidence       4118\n",
      "airline                            0\n",
      "name                               0\n",
      "retweet_count                      0\n",
      "text                               0\n",
      "tweet_created                      0\n",
      "tweet_location                  4733\n",
      "user_timezone                   4820\n",
      "dtype: int64\n",
      "tweet_id                         0.000000\n",
      "airline_sentiment                0.000000\n",
      "airline_sentiment_confidence     0.000000\n",
      "negativereason                  37.308743\n",
      "negativereason_confidence       28.128415\n",
      "airline                          0.000000\n",
      "name                             0.000000\n",
      "retweet_count                    0.000000\n",
      "text                             0.000000\n",
      "tweet_created                    0.000000\n",
      "tweet_location                  32.329235\n",
      "user_timezone                   32.923497\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check for more null values\n",
    "print(tweets.isnull().sum())\n",
    "\n",
    "print(((tweets.isnull().sum() * 100)/ len(tweets.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09edb117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_id, airline_sentiment, airline_sentiment_confidence, negativereason, negativereason_confidence, airline, name, retweet_count, text, tweet_created, tweet_location, user_timezone]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view negativereason column\n",
    "tweets[(tweets[\"negativereason\"].isnull()) & (tweets[\"airline_sentiment\"] == \"negative\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71efe84c",
   "metadata": {},
   "source": [
    "### The columns that are null from the \"negativereason\" column is because the \"airline_sentiment\" column is neutral or positive.\n",
    "\n",
    "Let's view the negativereason_confidence column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5006b09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_id, airline_sentiment, airline_sentiment_confidence, negativereason, negativereason_confidence, airline, name, retweet_count, text, tweet_created, tweet_location, user_timezone]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negativereason_confidence \n",
    "tweets[(tweets[\"negativereason_confidence\"].isnull())  & (tweets[\"airline_sentiment\"] == \"negative\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2041906",
   "metadata": {},
   "source": [
    "### The columns that are null from the \"negativereason_confidence\" column is because the \"airline_sentiment\" column is neutral or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6255e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "5  570300767074181121          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline      name  \\\n",
       "0            NaN                        NaN  Virgin America   cairdin   \n",
       "1            NaN                     0.0000  Virgin America  jnardino   \n",
       "3     Bad Flight                     0.7033  Virgin America  jnardino   \n",
       "4     Can't Tell                     1.0000  Virgin America  jnardino   \n",
       "5     Can't Tell                     0.6842  Virgin America  jnardino   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                @VirginAmerica What @dhepburn said.   \n",
       "1              0  @VirginAmerica plus you've added commercials t...   \n",
       "3              0  @VirginAmerica it's really aggressive to blast...   \n",
       "4              0  @VirginAmerica and it's a really big bad thing...   \n",
       "5              0  @VirginAmerica seriously would pay $30 a fligh...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n",
       "5  2015-02-24 11:14:33 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweet_location\n",
    "tweets[(tweets[\"tweet_location\"].isnull())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd65e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    3142\n",
       "neutral      962\n",
       "positive     629\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[(tweets[\"tweet_location\"].isnull())].groupby(\"airline_sentiment\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bead18a",
   "metadata": {},
   "source": [
    "Most of the null tweet location are from negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e565b",
   "metadata": {},
   "source": [
    "### The columns that are null from the \"tweet_location\" column is because the user more than likely do not have their locations on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d747c",
   "metadata": {},
   "source": [
    "Below is a view of all of the user_timezone column that is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "645b31b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    3170\n",
       "neutral      971\n",
       "positive     679\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view null user_timezone\n",
    "tweets[tweets[\"user_timezone\"].isnull()].groupby(\"airline_sentiment\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68215ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    1362\n",
       "neutral      430\n",
       "positive     357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_timezone > where the user timezone is null and the tweet location isn't null \n",
    "tzTweet = tweets[(tweets[\"user_timezone\"].isnull()) & (tweets[\"tweet_location\"].notnull())]\n",
    "\n",
    "tzTweet.groupby(\"airline_sentiment\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3580f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    1808\n",
       "neutral      541\n",
       "positive     322\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_timezone > where the user timezone is null and the tweet location is null \n",
    "timezoneTweet = tweets[(tweets[\"user_timezone\"].isnull()) & (tweets[\"tweet_location\"].isnull())]\n",
    "\n",
    "timezoneTweet.groupby(\"airline_sentiment\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0776df0",
   "metadata": {},
   "source": [
    "# 3. Data Definition <a class=\"anchor\" id=\"DataDefinition\"></a>\n",
    "\n",
    "                    \n",
    " 1   airline_sentiment              \n",
    " 2   airline_sentiment_confidence  \n",
    " 3   negativereason                 \n",
    " 4   negativereason_confidence    \n",
    " 5   airline                        \n",
    " 6   airline_sentiment_gold         \n",
    " 7   name                          \n",
    " 8   negativereason_gold            \n",
    " 9   retweet_count                 \n",
    " 10  text                           \n",
    " 11  tweet_coord                  \n",
    " 12  tweet_created                 \n",
    " 13  tweet_location                \n",
    " 14  user_timezone   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d78c2",
   "metadata": {},
   "source": [
    "# 4. Data Cleaning <a class=\"anchor\" id=\"DataCleaning\"></a>\n",
    "\n",
    "The following needs to be done to preprocess the data:\n",
    "\n",
    "1. Make text lowercase\n",
    "2. Removing punctuations, URLs, names\n",
    "3. Tokenization\n",
    "4. Removing stopwords (\"this\", \"is\", etc.)\n",
    "4. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77975914",
   "metadata": {},
   "source": [
    "### Lowercase\n",
    "Converting the \"text\" column to lowercase to help with preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ea5207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica what @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica i didn't today... must mean i n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline        name  \\\n",
       "0            NaN                        NaN  Virgin America     cairdin   \n",
       "1            NaN                     0.0000  Virgin America    jnardino   \n",
       "2            NaN                        NaN  Virgin America  yvonnalynn   \n",
       "3     Bad Flight                     0.7033  Virgin America    jnardino   \n",
       "4     Can't Tell                     1.0000  Virgin America    jnardino   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                @virginamerica what @dhepburn said.   \n",
       "1              0  @virginamerica plus you've added commercials t...   \n",
       "2              0  @virginamerica i didn't today... must mean i n...   \n",
       "3              0  @virginamerica it's really aggressive to blast...   \n",
       "4              0  @virginamerica and it's a really big bad thing...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].str.lower()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e8390",
   "metadata": {},
   "source": [
    "### Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3391dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @virginamerica what @dhepburn said.\n",
       "1    @virginamerica plus you've added commercials t...\n",
       "2    @virginamerica i didn't today... must mean i n...\n",
       "3    @virginamerica it's really aggressive to blast...\n",
       "4    @virginamerica and it's a really big bad thing...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove numbers\n",
    "tweets[\"text\"] = tweets[\"text\"].str.replace('\\d+', '', regex=True)\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be89c5",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7596a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    no_punct=[words for words in text if words not in string.punctuation]\n",
    "    words_wo_punct = ''.join(no_punct)\n",
    "    return words_wo_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a40a95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus youve added commercials to ...\n",
       "2    virginamerica i didnt today must mean i need t...\n",
       "3    virginamerica its really aggressive to blast o...\n",
       "4    virginamerica and its a really big bad thing a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove all of the punctuations\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: remove_punc(x))\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea3d78",
   "metadata": {},
   "source": [
    "### Remove whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28ba3022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus youve added commercials to ...\n",
       "2    virginamerica i didnt today must mean i need t...\n",
       "3    virginamerica its really aggressive to blast o...\n",
       "4    virginamerica and its a really big bad thing a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVE WHITESPACE\n",
    "tweets[\"text\"] = tweets[\"text\"].str.strip()\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ea419",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Split word to make a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f06fbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [virginamerica, what, dhepburn, said]\n",
       "1    [virginamerica, plus, youve, added, commercial...\n",
       "2    [virginamerica, i, didnt, today, must, mean, i...\n",
       "3    [virginamerica, its, really, aggressive, to, b...\n",
       "4    [virginamerica, and, its, a, really, big, bad,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token(text):\n",
    "    split=re.split(\"\\W\", text)\n",
    "    return split\n",
    "\n",
    "tweets['text'] = tweets[\"text\"].apply(lambda x: token(x))\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a3bb5",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "321b050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [word for word in text if word not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90125a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plus, youve, added, commercial...\n",
       "2    [virginamerica, didnt, today, must, mean, need...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: remove_stopwords(x))\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c915c",
   "metadata": {},
   "source": [
    "### Lemmatizing\n",
    "\n",
    "Reduce word to its root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01b63110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(x) for x in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "555e6c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plus, youve, added, commercial...\n",
       "2    [virginamerica, didnt, today, must, mean, need...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: word_lemmatizer(x))\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e14c94",
   "metadata": {},
   "source": [
    "### Langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "003d0aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langdetect import detect\\n\\n#turn into string object\\ntweets[\"text\"] = tweets[\"text\"].to_string()\\ntweets[\\'lang\\'] = tweets[\"text\"].apply(detect)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from langdetect import detect\n",
    "\n",
    "#turn into string object\n",
    "tweets[\"text\"] = tweets[\"text\"].to_string()\n",
    "tweets['lang'] = tweets[\"text\"].apply(detect)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "896ef67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets[tweets[\"lang\"] != 'en'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3122f3",
   "metadata": {},
   "source": [
    "All of the tweets are in english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df87ca",
   "metadata": {},
   "source": [
    "Emotion sensor features: https://www.kaggle.com/iwilldoit/emotions-sensor-data-setamount of repetition\n",
    "\n",
    "spell checking\n",
    "\n",
    "-emojis - convert to text version\n",
    "\n",
    "Text length\n",
    "\n",
    "% caps > 50%\n",
    "\n",
    "Look through the data yourself to see if you find any patterns that are indicative of a given class, make \n",
    "features out of those\n",
    "\n",
    "Semantic Role Labeller: https://cogcomp.seas.upenn.edu/page/software_view/Curator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b27654",
   "metadata": {},
   "source": [
    "### Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7b73158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import emoji\\n\\ntweets[\"text\"] = tweets[\"text\"].apply(lambda x: emoji.demojize(x))\\ntweets[\"text\"].head()'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import emoji\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: emoji.demojize(x))\n",
    "tweets[\"text\"].head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede23207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82ab39e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweets[\"text\"] = tweets[\"text\"].to_string() \\n\\ntweets[\\'text\\'] = tweets[\"text\"].apply(lambda x: token(x))\\ntweets[\"text\"].head()'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tweets[\"text\"] = tweets[\"text\"].to_string() \n",
    "\n",
    "tweets['text'] = tweets[\"text\"].apply(lambda x: token(x))\n",
    "tweets[\"text\"].head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5fe4e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, dhepburn, said]</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, plus, youve, added, commercial...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, didnt, today, must, mean, need...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, really, big, bad, thing]</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline        name  \\\n",
       "0            NaN                        NaN  Virgin America     cairdin   \n",
       "1            NaN                     0.0000  Virgin America    jnardino   \n",
       "2            NaN                        NaN  Virgin America  yvonnalynn   \n",
       "3     Bad Flight                     0.7033  Virgin America    jnardino   \n",
       "4     Can't Tell                     1.0000  Virgin America    jnardino   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                    [virginamerica, dhepburn, said]   \n",
       "1              0  [virginamerica, plus, youve, added, commercial...   \n",
       "2              0  [virginamerica, didnt, today, must, mean, need...   \n",
       "3              0  [virginamerica, really, aggressive, blast, obn...   \n",
       "4              0           [virginamerica, really, big, bad, thing]   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df234220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa2943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d15c0585",
   "metadata": {},
   "source": [
    "### spellcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04db43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.two.apply(lambda txt: ''.join(textblob.TextBlob(txt).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee271ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets[\"text\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7363563b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweets[\"text\"] = tweets[\"text\"].apply(lambda x: \\'\\'.join(textblob.TextBlob(x).correct()))\\ntweets[\"text\"].head(10)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tweets[\"text\"] = tweets[\"text\"].apply(lambda x: ''.join(textblob.TextBlob(x).correct()))\n",
    "tweets[\"text\"].head(10)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f217a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29058c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19933676",
   "metadata": {},
   "source": [
    "### Emotion sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f153b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install text2emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bf7a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import text2emotion as te\n",
    "#tweets[\"emotion\"] = te.get_emotion(tweets[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4264231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install text2emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80519e",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Try CountVec and Tfidf and choose which scores better on Logistic Regression/baseline model\n",
    "\n",
    "Make sure to pick min_df > 3 (at the very least) \n",
    "\n",
    "You can visualize document frequency by top words/n_grams and see at what min_df the words/phrases stop being sensible/interesting (Caseys Preprocessing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67eb18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bd4c1",
   "metadata": {},
   "source": [
    "### CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a2b3997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d53337d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39fc600a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'neutral'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4s/dkl5yc9543jbyd5lrgf388vh0000gp/T/ipykernel_3742/341713260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'airline_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'neutral'"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "cv = CountVectorizer(min_df=0.50)\n",
    "X = cv.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment'].values.astype('int64')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751c9f2",
   "metadata": {},
   "source": [
    "#### get base model with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression().fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"LR Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec1546",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d556862",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4s/dkl5yc9543jbyd5lrgf388vh0000gp/T/ipykernel_3742/3807492714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'airline_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[1;32m   1845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0m\u001b[1;32m   1222\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m   1093\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "td = TfidfVectorizer(max_df=0.95)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment'].values.astype(np.int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e074d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression().fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"LR Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd991f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b3a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05adaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# TfidfVectorizer \n",
    "# CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import pandas as pd\n",
    "# set of documents\n",
    "train = ['The sky is blue.','The sun is bright.']\n",
    "test = ['The sun in the sky is bright', 'We can see the shining sun, the bright sun.']\n",
    "# instantiate the vectorizer object\n",
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "# convert th documents into a matrix\n",
    "count_wm = countvectorizer.fit_transform(train)\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(train)\n",
    "#retrieve the terms found in the corpora\n",
    "# if we take same parameters on both Classes(CountVectorizer and TfidfVectorizer) , it will give same output of get_feature_names() methods)\n",
    "#count_tokens = tfidfvectorizer.get_feature_names() # no difference\n",
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "df_countvect = pd.DataFrame(data = count_wm.toarray(),index = ['Doc1','Doc2'],columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = ['Doc1','Doc2'],columns = tfidf_tokens)\n",
    "print(\"Count Vectorizer\\n\")\n",
    "print(df_countvect)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1e606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d013cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#your turn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "print(\"MN Accuracy: %0.2f%%\" % (100 * clf.score(xtest, ytest))\n",
    "      \n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac98754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4366e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2eeb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b74c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c823d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
