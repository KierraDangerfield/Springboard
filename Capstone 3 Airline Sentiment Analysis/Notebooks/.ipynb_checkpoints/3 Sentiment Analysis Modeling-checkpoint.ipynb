{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16b3d4e",
   "metadata": {},
   "source": [
    "# Airline Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4ae07",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Data Collection](#DataCollection)\n",
    "* [Data Organization](#DataOrganization)\n",
    "* [Data Definition](#DataDefinition)\n",
    "* [Data Cleaning](#DataCleaning)\n",
    "    * [Vectorization](#Vectorization)\n",
    "* [Model](#Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de85920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#this will deal with punctuation\n",
    "import string\n",
    "import re\n",
    "#from string import digits\n",
    "import nltk #using the Natural Language Toolkit\n",
    "from nltk.corpus import stopwords\n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9759f",
   "metadata": {},
   "source": [
    "# 1. Data Collection <a class=\"anchor\" id=\"DataCollection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af8dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "tweets = pd.read_csv(\"../Data/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034e195",
   "metadata": {},
   "source": [
    "# 2. Data Organization <a class=\"anchor\" id=\"DataOrganization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093c1148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the heading of data\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9520db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check shape\n",
    "print(tweets.shape)\n",
    "print(tweets.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e2c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id                            0\n",
      "airline_sentiment                   0\n",
      "airline_sentiment_confidence        0\n",
      "negativereason                   5462\n",
      "negativereason_confidence        4118\n",
      "airline                             0\n",
      "airline_sentiment_gold          14600\n",
      "name                                0\n",
      "negativereason_gold             14608\n",
      "retweet_count                       0\n",
      "text                                0\n",
      "tweet_coord                     13621\n",
      "tweet_created                       0\n",
      "tweet_location                   4733\n",
      "user_timezone                    4820\n",
      "dtype: int64\n",
      "tweet_id                         0.000000\n",
      "airline_sentiment                0.000000\n",
      "airline_sentiment_confidence     0.000000\n",
      "negativereason                  37.308743\n",
      "negativereason_confidence       28.128415\n",
      "airline                          0.000000\n",
      "airline_sentiment_gold          99.726776\n",
      "name                             0.000000\n",
      "negativereason_gold             99.781421\n",
      "retweet_count                    0.000000\n",
      "text                             0.000000\n",
      "tweet_coord                     93.039617\n",
      "tweet_created                    0.000000\n",
      "tweet_location                  32.329235\n",
      "user_timezone                   32.923497\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(tweets.isnull().sum())\n",
    "\n",
    "#percentage of null values\n",
    "print(((tweets.isnull().sum() * 100)/ len(tweets.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c45b9d",
   "metadata": {},
   "source": [
    "\"airline_sentiment_gold\" , \"negativereason_gold\", and \"tweet_coord\" columns are missing over 90% of their input. I will drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4799a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id                            0\n",
      "airline_sentiment                   0\n",
      "airline_sentiment_confidence        0\n",
      "negativereason                   5462\n",
      "negativereason_confidence        4118\n",
      "airline                             0\n",
      "airline_sentiment_gold          14600\n",
      "name                                0\n",
      "negativereason_gold             14608\n",
      "retweet_count                       0\n",
      "text                                0\n",
      "tweet_coord                     13621\n",
      "tweet_created                       0\n",
      "tweet_location                   4733\n",
      "user_timezone                    4820\n",
      "dtype: int64\n",
      "tweet_id                         0.000000\n",
      "airline_sentiment                0.000000\n",
      "airline_sentiment_confidence     0.000000\n",
      "negativereason                  37.308743\n",
      "negativereason_confidence       28.128415\n",
      "airline                          0.000000\n",
      "airline_sentiment_gold          99.726776\n",
      "name                             0.000000\n",
      "negativereason_gold             99.781421\n",
      "retweet_count                    0.000000\n",
      "text                             0.000000\n",
      "tweet_coord                     93.039617\n",
      "tweet_created                    0.000000\n",
      "tweet_location                  32.329235\n",
      "user_timezone                   32.923497\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check for more null values\n",
    "print(tweets.isnull().sum())\n",
    "\n",
    "print(((tweets.isnull().sum() * 100)/ len(tweets.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0776df0",
   "metadata": {},
   "source": [
    "# 3. Data Definition <a class=\"anchor\" id=\"DataDefinition\"></a>\n",
    "\n",
    "                    \n",
    " 1   airline_sentiment              \n",
    " 2   airline_sentiment_confidence  \n",
    " 3   negativereason                 \n",
    " 4   negativereason_confidence    \n",
    " 5   airline                        \n",
    " 6   airline_sentiment_gold         \n",
    " 7   name                          \n",
    " 8   negativereason_gold            \n",
    " 9   retweet_count                 \n",
    " 10  text                           \n",
    " 11  tweet_coord                  \n",
    " 12  tweet_created                 \n",
    " 13  tweet_location                \n",
    " 14  user_timezone   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d78c2",
   "metadata": {},
   "source": [
    "# 4. Data Cleaning <a class=\"anchor\" id=\"DataCleaning\"></a>\n",
    "\n",
    "The following needs to be done to preprocess the data:\n",
    "\n",
    "1. Make text lowercase\n",
    "2. Removing punctuations, URLs, names\n",
    "3. Tokenization\n",
    "4. Removing stopwords (\"this\", \"is\", etc.)\n",
    "4. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ea5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase\n",
    "tweets[\"text\"] = tweets[\"text\"].str.lower()\n",
    "\n",
    "#remove numbers\n",
    "tweets[\"text\"] = tweets[\"text\"].str.replace('\\d+', '', regex=True)\n",
    "\n",
    "##REMOVE PUNCTUATIONS\n",
    "def remove_punc(text):\n",
    "    words_wo_punct = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", text)\n",
    "    return words_wo_punct\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: remove_punc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b03e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus youve added commercials to ...\n",
       "2    virginamerica i didnt today must mean i need t...\n",
       "3    virginamerica its really aggressive to blast o...\n",
       "4    virginamerica and its a really big bad thing a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVE WHITESPACE\n",
    "tweets[\"text\"] = tweets[\"text\"].str.strip()\n",
    "\n",
    "#remove emoji\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: emoji.demojize(x))\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3391dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus youve added commercial to t...\n",
       "2    virginamerica i didnt today must mean i need t...\n",
       "3    virginamerica it really aggressive to blast ob...\n",
       "4    virginamerica and it a really big bad thing ab...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LEMMATIZING\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lem_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lem_text\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: word_lemmatizer(x))\n",
    "tweets.text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb1a29",
   "metadata": {},
   "source": [
    "## Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c22d054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica what dhepburn said</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica plus youve added commercial to t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica i didnt today must mean i need t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>-0.3125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                   virginamerica what dhepburn said         NaN   \n",
       "1  virginamerica plus youve added commercial to t...         NaN   \n",
       "2  virginamerica i didnt today must mean i need t...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)   \n",
       "\n",
       "   polarity  \n",
       "0    0.0000  \n",
       "1    0.0000  \n",
       "2   -0.3125  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob, Word, Blobber\n",
    "tweets['polarity']=tweets['text'].map(lambda text: TextBlob(str(text)).sentiment.polarity)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5b18b",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9e97ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica what dhepburn said</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica plus youve added commercial to t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica i didnt today must mean i need t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                   virginamerica what dhepburn said         NaN   \n",
       "1  virginamerica plus youve added commercial to t...         NaN   \n",
       "2  virginamerica i didnt today must mean i need t...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)   \n",
       "\n",
       "   polarity  word_count  \n",
       "0    0.0000          32  \n",
       "1    0.0000          65  \n",
       "2   -0.3125          65  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a word count per sentence column\n",
    "def wordCount(text):\n",
    "    return len(text)\n",
    "\n",
    "tweets[\"word_count\"] = tweets[\"text\"].apply(lambda x: wordCount(x))\n",
    "\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30186610",
   "metadata": {},
   "source": [
    "### Vectorization <a class=\"anchor\" id=\"Vectorization\"></a>\n",
    "\n",
    "Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9d6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebcf8b",
   "metadata": {},
   "source": [
    "### CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a66efe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89983bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change text to string\n",
    "tweets[\"text\"] = tweets[\"text\"].astype(str)\n",
    "\n",
    "#change sentiment to int\n",
    "\n",
    "def changeSentiment(sentiment):\n",
    "    if  sentiment == \"positive\":\n",
    "        return 1\n",
    "    elif sentiment == \"neutral\":\n",
    "        return 0\n",
    "    elif sentiment == \"negative\":\n",
    "        return -1\n",
    "    \n",
    "tweets['airline_sentiment'] = tweets['airline_sentiment'].apply(lambda x : changeSentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01192ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "\n",
    "cv = CountVectorizer(max_df=0.70)\n",
    "X = cv.fit_transform(tweets.text)\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611ae14",
   "metadata": {},
   "source": [
    "#### get base model with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2a1e1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 79.87%\n",
      "Accuracy on training data: 0.95\n",
      "Accuracy on test data:     0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e7177",
   "metadata": {},
   "source": [
    "### Tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d8905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bfb15e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 80.37%\n",
      "Accuracy on training data: 0.89\n",
      "Accuracy on test data:     0.80\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56a743",
   "metadata": {},
   "source": [
    "Vectorizing with Tfidf performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "256a9940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dhepburn</th>\n",
       "      <td>0.774839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>0.424804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginamerica</th>\n",
       "      <td>0.340311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>0.321487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pacificbiznews</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghettofab</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gi</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>giannilee</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>giant</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurichnew</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13587 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TF-IDF\n",
       "dhepburn        0.774839\n",
       "said            0.424804\n",
       "virginamerica   0.340311\n",
       "what            0.321487\n",
       "pacificbiznews  0.000000\n",
       "...                  ...\n",
       "ghettofab       0.000000\n",
       "gi              0.000000\n",
       "giannilee       0.000000\n",
       "giant           0.000000\n",
       "zurichnew       0.000000\n",
       "\n",
       "[13587 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF Scores\n",
    "df = pd.DataFrame(X[0].T.todense(), index=td.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ce620",
   "metadata": {},
   "source": [
    "# Model <a class=\"anchor\" id=\"Model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c3acc",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04749e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22f7d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 66.96%\n",
      "Accuracy on training data: 0.70\n",
      "Accuracy on test data:     0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB().fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Naive Bayes Accuracy: %0.2f%%\" % (100 * mnb.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = mnb.score(X_train, y_train)\n",
    "test_accuracy = mnb.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e5dcb",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ae3ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4c18878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 74.77%\n",
      "Accuracy on training data: 1.00\n",
      "Accuracy on test data:     0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Random Forest Accuracy: %0.2f%%\" % (100 * rf.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = rf.score(X_train, y_train)\n",
    "test_accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d39d47",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The Logistic Regression model performed the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e48d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(min_df=5, max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74388de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10248x2717 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 146722 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b31452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 80.53%\n",
      "Accuracy on training data: 0.86\n",
      "Accuracy on test data:     0.81\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ede89",
   "metadata": {},
   "source": [
    "The base model performed the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0c823",
   "metadata": {},
   "source": [
    "## Let's improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8ad5d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, ..., -1, -1,  0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'C' : [.01, .001, 1],#, 10, 100],\n",
    "    'max_iter': [1000]\n",
    "    #'penalty' : ['l1', 'l2']\"\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(LogisticRegression(), parameters, cv=5) \n",
    "lr_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \" % lr_gs.best_params_)\n",
    "print(\"Accuracy: \" % lr_gs.best_score_)\n",
    "lr_gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e05994e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8631928181108509"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(lr_gs.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cb9668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a88c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
