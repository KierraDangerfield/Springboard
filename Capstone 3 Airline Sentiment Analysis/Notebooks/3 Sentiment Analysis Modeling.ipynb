{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16b3d4e",
   "metadata": {},
   "source": [
    "# Airline Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4ae07",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Data Collection](#DataCollection)\n",
    "* [Data Organization](#DataOrganization)\n",
    "* [Data Definition](#DataDefinition)\n",
    "* [Data Cleaning](#DataCleaning)\n",
    "    * [Vectorization](#Vectorization)\n",
    "* [Model](#Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de85920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#this will deal with punctuation\n",
    "import string\n",
    "import re\n",
    "#from string import digits\n",
    "import nltk #using the Natural Language Toolkit\n",
    "from nltk.corpus import stopwords\n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9759f",
   "metadata": {},
   "source": [
    "# 1. Data Collection <a class=\"anchor\" id=\"DataCollection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af8dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "tweets = pd.read_csv(\"../Data/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034e195",
   "metadata": {},
   "source": [
    "# 2. Data Organization <a class=\"anchor\" id=\"DataOrganization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093c1148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the heading of data\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9520db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check shape\n",
    "print(tweets.shape)\n",
    "print(tweets.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e2c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id                            0\n",
      "airline_sentiment                   0\n",
      "airline_sentiment_confidence        0\n",
      "negativereason                   5462\n",
      "negativereason_confidence        4118\n",
      "airline                             0\n",
      "airline_sentiment_gold          14600\n",
      "name                                0\n",
      "negativereason_gold             14608\n",
      "retweet_count                       0\n",
      "text                                0\n",
      "tweet_coord                     13621\n",
      "tweet_created                       0\n",
      "tweet_location                   4733\n",
      "user_timezone                    4820\n",
      "dtype: int64\n",
      "tweet_id                         0.000000\n",
      "airline_sentiment                0.000000\n",
      "airline_sentiment_confidence     0.000000\n",
      "negativereason                  37.308743\n",
      "negativereason_confidence       28.128415\n",
      "airline                          0.000000\n",
      "airline_sentiment_gold          99.726776\n",
      "name                             0.000000\n",
      "negativereason_gold             99.781421\n",
      "retweet_count                    0.000000\n",
      "text                             0.000000\n",
      "tweet_coord                     93.039617\n",
      "tweet_created                    0.000000\n",
      "tweet_location                  32.329235\n",
      "user_timezone                   32.923497\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(tweets.isnull().sum())\n",
    "\n",
    "#percentage of null values\n",
    "print(((tweets.isnull().sum() * 100)/ len(tweets.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c45b9d",
   "metadata": {},
   "source": [
    "\"airline_sentiment_gold\" , \"negativereason_gold\", and \"tweet_coord\" columns are missing over 90% of their input. I will drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5843f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id                           0\n",
      "airline_sentiment                  0\n",
      "airline_sentiment_confidence       0\n",
      "negativereason                  5462\n",
      "negativereason_confidence       4118\n",
      "airline                            0\n",
      "name                               0\n",
      "retweet_count                      0\n",
      "text                               0\n",
      "tweet_created                      0\n",
      "tweet_location                  4733\n",
      "user_timezone                   4820\n",
      "dtype: int64\n",
      "tweet_id                         0.000000\n",
      "airline_sentiment                0.000000\n",
      "airline_sentiment_confidence     0.000000\n",
      "negativereason                  37.308743\n",
      "negativereason_confidence       28.128415\n",
      "airline                          0.000000\n",
      "name                             0.000000\n",
      "retweet_count                    0.000000\n",
      "text                             0.000000\n",
      "tweet_created                    0.000000\n",
      "tweet_location                  32.329235\n",
      "user_timezone                   32.923497\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.drop(columns=[\"airline_sentiment_gold\" , \"negativereason_gold\", \"tweet_coord\"])\n",
    "\n",
    "#check for more null values\n",
    "print(tweets.isnull().sum())\n",
    "\n",
    "print(((tweets.isnull().sum() * 100)/ len(tweets.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4799a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0776df0",
   "metadata": {},
   "source": [
    "# 3. Data Definition <a class=\"anchor\" id=\"DataDefinition\"></a>\n",
    "\n",
    "                    \n",
    " 1   airline_sentiment              \n",
    " 2   airline_sentiment_confidence  \n",
    " 3   negativereason                 \n",
    " 4   negativereason_confidence    \n",
    " 5   airline                        \n",
    " 6   airline_sentiment_gold         \n",
    " 7   name                          \n",
    " 8   negativereason_gold            \n",
    " 9   retweet_count                 \n",
    " 10  text                           \n",
    " 11  tweet_coord                  \n",
    " 12  tweet_created                 \n",
    " 13  tweet_location                \n",
    " 14  user_timezone   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d78c2",
   "metadata": {},
   "source": [
    "# 4. Data Cleaning <a class=\"anchor\" id=\"DataCleaning\"></a>\n",
    "\n",
    "The following needs to be done to preprocess the data:\n",
    "\n",
    "1. Make text lowercase\n",
    "2. Removing punctuations, URLs, names\n",
    "3. Tokenization\n",
    "4. Removing stopwords (\"this\", \"is\", etc.)\n",
    "4. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ea5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase\n",
    "tweets[\"text\"] = tweets[\"text\"].str.lower()\n",
    "\n",
    "#remove numbers\n",
    "tweets[\"text\"] = tweets[\"text\"].str.replace('\\d+', '', regex=True)\n",
    "\n",
    "##REMOVE PUNCTUATIONS\n",
    "def remove_punc(text):\n",
    "    words_wo_punct = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", text)\n",
    "    return words_wo_punct\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: remove_punc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b03e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus youve added commercials to ...\n",
       "2    virginamerica i didnt today must mean i need t...\n",
       "3    virginamerica its really aggressive to blast o...\n",
       "4    virginamerica and its a really big bad thing a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVE WHITESPACE\n",
    "tweets[\"text\"] = tweets[\"text\"].str.strip()\n",
    "\n",
    "#remove emoji\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: emoji.demojize(x))\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3391dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus youve added commercial to t...\n",
       "2    virginamerica i didnt today must mean i need t...\n",
       "3    virginamerica it really aggressive to blast ob...\n",
       "4    virginamerica and it a really big bad thing ab...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LEMMATIZING\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lem_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lem_text\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: word_lemmatizer(x))\n",
    "tweets.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c1e69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plus, youve, added, commercial...\n",
       "2    [virginamerica, didnt, today, must, mean, need...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVE STOPWORDS and tokenize\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    tokens_wo_stopwords = [t for t in tokens if t not in english_stopwords]\n",
    "    \n",
    "    return tokens_wo_stopwords\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: remove_stopwords(str(x)))\n",
    "tweets[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb1a29",
   "metadata": {},
   "source": [
    "## Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c22d054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, dhepburn, said]</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, plus, youve, added, commercial...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>[virginamerica, didnt, today, must, mean, need...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>-0.3125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline        name  \\\n",
       "0            NaN                        NaN  Virgin America     cairdin   \n",
       "1            NaN                        0.0  Virgin America    jnardino   \n",
       "2            NaN                        NaN  Virgin America  yvonnalynn   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                    [virginamerica, dhepburn, said]   \n",
       "1              0  [virginamerica, plus, youve, added, commercial...   \n",
       "2              0  [virginamerica, didnt, today, must, mean, need...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)   \n",
       "\n",
       "   polarity  \n",
       "0    0.0000  \n",
       "1    0.0000  \n",
       "2   -0.3125  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob, Word, Blobber\n",
    "tweets['polarity']=tweets['text'].map(lambda text: TextBlob(str(text)).sentiment.polarity)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30186610",
   "metadata": {},
   "source": [
    "### Vectorization <a class=\"anchor\" id=\"Vectorization\"></a>\n",
    "\n",
    "Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9d6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebcf8b",
   "metadata": {},
   "source": [
    "### CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89983bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change text to string\n",
    "tweets[\"text\"] = tweets[\"text\"].astype(str)\n",
    "\n",
    "#change sentiment to int\n",
    "\n",
    "def changeSentiment(sentiment):\n",
    "    if  sentiment == \"positive\":\n",
    "        return 1\n",
    "    elif sentiment == \"neutral\":\n",
    "        return 0\n",
    "    elif sentiment == \"negative\":\n",
    "        return -1\n",
    "    \n",
    "tweets['airline_sentiment'] = tweets['airline_sentiment'].apply(lambda x : changeSentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01192ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "\n",
    "cv = CountVectorizer(max_df=0.70)\n",
    "X = cv.fit_transform(tweets.text)\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611ae14",
   "metadata": {},
   "source": [
    "#### get base model with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a1e1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 77.21%\n",
      "Accuracy on training data: 0.95\n",
      "Accuracy on test data:     0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e7177",
   "metadata": {},
   "source": [
    "### Tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d8905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bfb15e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 77.91%\n",
      "Accuracy on training data: 0.88\n",
      "Accuracy on test data:     0.78\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56a743",
   "metadata": {},
   "source": [
    "Vectorizing with Tfidf performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256a9940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dhepburn</th>\n",
       "      <td>0.818278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>0.448619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginamerica</th>\n",
       "      <td>0.359390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owen</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owes</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gfc</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gg</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ggqzqd</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ggreenwald</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurichnew</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13466 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TF-IDF\n",
       "dhepburn       0.818278\n",
       "said           0.448619\n",
       "virginamerica  0.359390\n",
       "owen           0.000000\n",
       "owes           0.000000\n",
       "...                 ...\n",
       "gfc            0.000000\n",
       "gg             0.000000\n",
       "ggqzqd         0.000000\n",
       "ggreenwald     0.000000\n",
       "zurichnew      0.000000\n",
       "\n",
       "[13466 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF Scores\n",
    "df = pd.DataFrame(X[0].T.todense(), index=td.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ce620",
   "metadata": {},
   "source": [
    "# Model <a class=\"anchor\" id=\"Model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c3acc",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04749e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a22f7d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 67.90%\n",
      "Accuracy on training data: 0.72\n",
      "Accuracy on test data:     0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB().fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Naive Bayes Accuracy: %0.2f%%\" % (100 * mnb.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = mnb.score(X_train, y_train)\n",
    "test_accuracy = mnb.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e5dcb",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ae3ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4c18878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 75.07%\n",
      "Accuracy on training data: 1.00\n",
      "Accuracy on test data:     0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Random Forest Accuracy: %0.2f%%\" % (100 * rf.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = rf.score(X_train, y_train)\n",
    "test_accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2e190",
   "metadata": {},
   "source": [
    "## Lets Improve the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c85d4457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 100, 'max_features': 'auto', 'n_estimators': 300}\n",
      "0.736533276196598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'max_depth': [50, 100], \n",
    "    'max_features': ['auto'], \n",
    "    'n_estimators': [300, 400]\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(rf, parameters, cv=5) \n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "print(rf_gs.best_params_)\n",
    "print(rf_gs.best_score_)\n",
    "rf_gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d90a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 74.64%\n",
      "Accuracy on training data: 0.96\n",
      "Accuracy on test data:     0.75\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth= 100, max_features= 'auto', n_estimators = 300).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Random Forest Accuracy: %0.2f%%\" % (100 * rf.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = rf.score(X_train, y_train)\n",
    "test_accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d39d47",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The Logistic Regression model performed the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e48d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(min_df=5, max_df=0.70)\n",
    "X = td.fit_transform(tweets['text'])\n",
    "y = tweets['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74388de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10248x2606 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 89955 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b31452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 77.73%\n",
      "Accuracy on training data: 0.86\n",
      "Accuracy on test data:     0.78\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ede89",
   "metadata": {},
   "source": [
    "## The base model performed the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0c823",
   "metadata": {},
   "source": [
    "## Let's improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8ad5d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'max_iter': 1000}\n",
      "0.7889337842987805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1, ..., -1, -1,  1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'C' : [.01, .001, 1, 10, 100],#, 10, 100],\n",
    "    'max_iter': [1000],\n",
    "    #'penalty' : ['l1', 'l2']\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(logReg, parameters, cv=10) \n",
    "lr_gs.fit(X_train, y_train)\n",
    "\n",
    "print(lr_gs.best_params_)\n",
    "print(lr_gs.best_score_)\n",
    "lr_gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e05994e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(lr_gs.predict(X_train), y_train)\n",
    "#logReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cb9668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 77.73%\n",
      "Accuracy on training data: 0.86\n",
      "Accuracy on test data:     0.78\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(max_iter=1000, C=1).fit(X_train, y_train)\n",
    "#print accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %0.2f%%\" % (100 * logReg.score(X_test, y_test)))\n",
    "\n",
    "training_accuracy = logReg.score(X_train, y_train)\n",
    "test_accuracy = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
